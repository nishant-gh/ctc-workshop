{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 0: Hello, AI!\n",
    "\n",
    "Welcome! In this workshop, you'll have a conversation with an AI — and discover a few surprising things about how it actually works.\n",
    "\n",
    "**You don't need to write any code.** Everything is pre-written. You just press **Shift+Enter** to run each cell and observe what happens.\n",
    "\n",
    "Let's start by setting things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected! Using model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# Just run this cell! Press Shift+Enter\n",
    "# This connects us to the AI service\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\") or os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"ANTHROPIC_API_KEY\") or os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if API_KEY and API_KEY.startswith(\"sk-ant-\"):\n",
    "    BASE_URL = \"https://api.anthropic.com/v1/\"\n",
    "    MODEL = \"claude-sonnet-4-20250514\"\n",
    "elif API_KEY and API_KEY.startswith(\"sk-\"):\n",
    "    BASE_URL = \"https://api.openai.com/v1\"\n",
    "    MODEL = \"gpt-4o\"\n",
    "else:\n",
    "    BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "BASE_URL = os.getenv(\"OPENAI_BASE_URL\", BASE_URL)\n",
    "MODEL = os.getenv(\"MODEL\", MODEL)\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)\n",
    "\n",
    "print(f\"Connected! Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Talking to an AI\n",
    "\n",
    "Talking to an AI is a lot like **sending a text message**. You type something, send it, and get a reply back.\n",
    "\n",
    "Behind the scenes, your message goes to an AI model (like ChatGPT, Claude, or Gemini), and it sends back a response. That's it. No magic — just a request and a response.\n",
    "\n",
    "Let's send our first message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell! Press Shift+Enter\n",
    "# We're sending a simple message to the AI\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What are three fun facts about the Moon?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's it!** You just sent a message to an AI and got a reply.\n",
    "\n",
    "Every AI product you've ever used — ChatGPT, Copilot, Gemini — is doing exactly this under the hood: sending messages and receiving responses.\n",
    "\n",
    "Now let's discover something surprising about how the AI's memory works..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: AI Has No Memory\n",
    "\n",
    "Imagine you're texting someone who has **complete amnesia after every message**. Each time you text them, they have zero recollection of anything you've said before. It's like talking to a goldfish with a PhD.\n",
    "\n",
    "Sounds weird, right? Let's see it in action.\n",
    "\n",
    "**Step 1:** We'll introduce ourselves to the AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell! Press Shift+Enter\n",
    "# Let's tell the AI our name\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hi there! My name is Ralph. Nice to meet you!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, the AI greeted us by name. It clearly knows who we are.\n",
    "\n",
    "**Step 2:** Now let's ask it what our name is — in a *separate* message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell! Press Shift+Enter\n",
    "# Let's ask the AI if it remembers our name\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait... it forgot?!\n",
    "\n",
    "**Yes!** The AI has absolutely no memory between calls. Each time you send a message, it's a brand new conversation. The AI has never seen you before.\n",
    "\n",
    "This is one of the most important things to understand about AI:\n",
    "\n",
    "> **Every single request to an AI starts from scratch.** It doesn't remember anything unless *you* remind it.\n",
    "\n",
    "Think about what this means for products like ChatGPT. When you have a long conversation, the AI doesn't actually *remember* any of it. So how does it seem like it does?\n",
    "\n",
    "Let's find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: The Chat History Trick\n",
    "\n",
    "Here's the trick: **we keep a notebook of the entire conversation and show it to the AI every single time.**\n",
    "\n",
    "Imagine you're texting that amnesiac friend again. But this time, before every message, you copy-paste the *entire conversation so far* at the top. Now your friend can read the history and respond as if they remember everything.\n",
    "\n",
    "That's exactly what ChatGPT does behind the scenes. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell! Press Shift+Enter\n",
    "# This time we send the FULL conversation history\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hi there! My name is Ralph. Nice to meet you!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hello Ralph! Nice to meet you too! How can I help you today?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It remembers!\n",
    "\n",
    "But it doesn't *really* remember. We just **showed it the full conversation** and it read through it to give us a consistent answer.\n",
    "\n",
    "This is exactly how every AI chatbot works:\n",
    "1. You send a message\n",
    "2. The app stores the message in a list\n",
    "3. Next time, the app sends the **entire list** back to the AI\n",
    "4. The AI reads the whole thing and responds\n",
    "\n",
    "### But there's a catch...\n",
    "\n",
    "This \"notebook\" has a **limited number of pages**. You can't copy-paste an infinite conversation. At some point, you run out of space.\n",
    "\n",
    "This limit is called the **context window** — it's the maximum amount of text the AI can read at once. Think of it like a desk: you can only spread out so many papers before things start falling off the edges.\n",
    "\n",
    "| Model | Context Window | Rough Equivalent |\n",
    "|-------|---------------|-------------------|\n",
    "| GPT-4o | 128K tokens | ~200 pages of text |\n",
    "| Claude Sonnet | 200K tokens | ~300 pages of text |\n",
    "| Gemini Flash | 1M tokens | ~1,500 pages of text |\n",
    "\n",
    "**PM Insight:** When you're evaluating an AI product, ask: *\"How does it handle conversations that exceed the context window?\"* The answer reveals a lot about how thoughtfully the product was built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: The System Prompt — Giving AI a Personality\n",
    "\n",
    "So far we've been sending messages as the `user`. But there's a special type of message called the **system prompt**. It's like giving the AI a job description before the conversation starts.\n",
    "\n",
    "Think of it this way:\n",
    "- The **system prompt** is like a director's brief to an actor: *\"You're playing a pirate captain in this scene.\"*\n",
    "- The **user messages** are the lines from the other actors.\n",
    "\n",
    "The AI will stay in character for the whole conversation based on the system prompt.\n",
    "\n",
    "Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell! Press Shift+Enter\n",
    "# We give the AI a \"personality\" using a system prompt\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a pirate captain. Respond to everything in pirate speak. Use plenty of 'arrr', 'matey', and 'shiver me timbers'. Keep responses short and fun.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the best programming language?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn! Try changing the personality.\n",
    "\n",
    "In the cell below, **edit the system prompt** to make the AI talk like someone else. Some ideas:\n",
    "- A Bollywood villain delivering a monologue\n",
    "- An over-excited cricket commentator\n",
    "- A Shakespearean poet\n",
    "- A motivational gym coach\n",
    "- Your favourite movie character\n",
    "\n",
    "Just change the text inside the quotes next to `\"content\":` in the system message, then press **Shift+Enter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the system prompt below, then press Shift+Enter to run!\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a dramatic Bollywood villain. Every response must include a dramatic pause (...), a reference to destiny, and end with an evil laugh. Keep it fun and over-the-top.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Should I learn about AI?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PM Insight:** The system prompt is incredibly powerful. In real products, this is where you define:\n",
    "- The AI's tone and personality (friendly? formal? fun?)\n",
    "- What the AI should and shouldn't talk about\n",
    "- How it should format responses\n",
    "- Safety guardrails and boundaries\n",
    "\n",
    "When you're building an AI product, the system prompt is essentially your **product requirements document for the AI's behavior**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Recap — What You Just Learned\n",
    "\n",
    "You've just discovered the core building blocks that power every AI product. Let's recap:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**1. Talking to AI = sending a message and getting a response**\n",
    "> Under the hood, every AI interaction is just an API call. The fancy chat interfaces you see are just wrappers around this simple exchange.\n",
    "\n",
    "**2. AI is stateless — it has no memory**\n",
    "> Every request starts from zero. The AI doesn't remember past conversations. *You* (the product) must manage the conversation history.\n",
    "\n",
    "**3. The \"memory\" trick = sending the full chat history every time**\n",
    "> Products like ChatGPT make AI *seem* like it remembers by replaying the entire conversation with each request.\n",
    "\n",
    "**4. Context window = limited memory budget**\n",
    "> There's a hard limit on how much text the AI can process at once. Longer conversations and bigger documents mean tougher design decisions.\n",
    "\n",
    "**5. System prompt = product requirements for AI behavior**\n",
    "> This is where you shape the AI's personality, boundaries, and behavior. It's one of the most important levers in AI product design.\n",
    "\n",
    "---\n",
    "\n",
    "**These five concepts are the foundation of every AI agent.** In the next workshops, we'll build on them to create AI that can use tools, make decisions, and work autonomously."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
