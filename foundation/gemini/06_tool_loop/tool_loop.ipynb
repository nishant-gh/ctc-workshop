{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab; uses env var already set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Exercise 6: The Agentic Loop\n",
    "\n",
    "In this exercise, we put it all together into an **agent loop** — the core pattern behind AI agents.\n",
    "\n",
    "By the end, you'll understand:\n",
    "- How to build a loop that keeps running until the model stops requesting tools\n",
    "- How to dispatch tool calls to actual functions\n",
    "- How the model can chain **multiple** tool calls to answer a single question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from datetime import datetime\n",
    "\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Define multiple tools and a dispatcher\n",
    "\n",
    "This time we have **two** tools. The `call_tool` function maps tool names to their implementations — this is how real agents work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather in a given location.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_time() -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def call_tool(tool_name, tool_input):\n",
    "    if tool_name == \"get_weather\":\n",
    "        return f\"72°F and sunny in {tool_input['location']}\"\n",
    "    elif tool_name == \"get_time\":\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        return \"Tool not found.\"\n",
    "\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[get_weather, get_time],\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: The agent loop\n",
    "\n",
    "This is the core pattern. The loop:\n",
    "1. Sends contents to the model\n",
    "2. Checks if the response contains any `function_call` parts\n",
    "3. If yes — executes each tool, appends results, and loops back to step 1\n",
    "4. If no — the model is done, we print the final text and break\n",
    "\n",
    "Because we ask about **both** weather and time, the model needs to call two tools — watch the loop iterate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [types.Content(role=\"user\", parts=[types.Part.from_text(text=\"What's the weather and current time in Tokyo?\")])]\n",
    "\n",
    "loop_count = 0\n",
    "\n",
    "while True:\n",
    "    loop_count += 1\n",
    "    print(f\"--- Loop iteration {loop_count} ---\")\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        contents=contents,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    model_content = response.candidates[0].content\n",
    "    contents.append(model_content)\n",
    "\n",
    "    function_calls = [part.function_call for part in model_content.parts if part.function_call]\n",
    "\n",
    "    if function_calls:\n",
    "        tool_response_parts = []\n",
    "        for fc in function_calls:\n",
    "            tool_result = call_tool(fc.name, dict(fc.args))\n",
    "            print(f\"  Tool: {fc.name}({dict(fc.args)}) → {tool_result}\")\n",
    "            tool_response_parts.append(\n",
    "                types.Part.from_function_response(name=fc.name, response={\"output\": tool_result})\n",
    "            )\n",
    "        contents.append(types.Content(role=\"user\", parts=tool_response_parts))\n",
    "    else:\n",
    "        print(f\"\\n{response.text}\")\n",
    "        print(\"\\nDone! No more tool calls.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Review the full message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in contents:\n",
    "    print(f\"--- {msg.role} ---\")\n",
    "    for part in msg.parts:\n",
    "        if part.text:\n",
    "            print(part.text)\n",
    "        elif part.function_call:\n",
    "            print(f\"[function_call: {part.function_call.name}({part.function_call.args})]\")\n",
    "        elif part.function_response:\n",
    "            print(f\"[function_response: {part.function_response.name} → {part.function_response.response}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Key takeaway\n",
    "\n",
    "This is the **agentic loop** — the foundation of every AI agent:\n",
    "\n",
    "```\n",
    "while True:\n",
    "    response = call_model(contents)\n",
    "    if response has function calls:\n",
    "        execute tools, append results\n",
    "    else:\n",
    "        break  # model is done\n",
    "```\n",
    "\n",
    "Everything else — multiple tools, error handling, human-in-the-loop, memory — is built on top of this pattern.\n",
    "\n",
    "Now let's build some real agents!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
