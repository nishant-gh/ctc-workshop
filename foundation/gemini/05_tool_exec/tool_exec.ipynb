{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab; uses env var already set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Exercise 5: Executing a Tool\n",
    "\n",
    "In the previous exercise, the model asked us to call a tool. Now we'll complete the round-trip: execute the tool and send the result back.\n",
    "\n",
    "By the end, you'll understand:\n",
    "- How to append the model's function-call response to the contents list\n",
    "- How to construct a `FunctionResponse` part with the result\n",
    "- The full request/response cycle for tool use in Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup (same as previous exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather in a given location.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[get_weather],\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Get the tool-call response\n",
    "\n",
    "Note: we use explicit `Content` objects so we can build the multi-turn conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [types.Content(role=\"user\", parts=[types.Part.from_text(text=\"What is the weather in Tokyo?\")])]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=contents,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "model_content = response.candidates[0].content\n",
    "print(f\"Parts: {model_content.parts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Append the model's response\n",
    "\n",
    "**Important:** You must append the full model content object. This preserves the `function_call` parts, which the API needs to match tool results back to their requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents.append(model_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Find the function call and \"execute\" the tool\n",
    "\n",
    "In a real application, you'd call an actual weather API here. For now, we return a hardcoded result.\n",
    "\n",
    "Note: `function_call.args` is already a **dict** — no JSON parsing needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = model_content.parts[0].function_call\n",
    "\n",
    "print(f\"The model wants to call: {fc.name}\")\n",
    "print(f\"With arguments: {fc.args}\")\n",
    "\n",
    "# \"Execute\" the tool (hardcoded for now)\n",
    "tool_result = \"65 degrees\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 5: Send the tool result back\n",
    "\n",
    "We send the result as a `Content` with a `FunctionResponse` part. The `name` must match the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents.append(\n",
    "    types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part.from_function_response(name=fc.name, response={\"output\": tool_result})],\n",
    "    )\n",
    ")\n",
    "\n",
    "final_response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=contents,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(final_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 6: Review the full message flow\n",
    "\n",
    "Let's look at the complete conversation to see the three-step pattern:\n",
    "1. **User** asks a question\n",
    "2. **Model** responds with a `function_call`\n",
    "3. **User** sends back a `FunctionResponse`\n",
    "4. **Model** gives the final natural language answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents.append(final_response.candidates[0].content)\n",
    "\n",
    "for msg in contents:\n",
    "    print(f\"--- {msg.role} ---\")\n",
    "    for part in msg.parts:\n",
    "        if part.text:\n",
    "            print(part.text)\n",
    "        elif part.function_call:\n",
    "            print(f\"[function_call: {part.function_call.name}({part.function_call.args})]\")\n",
    "        elif part.function_response:\n",
    "            print(f\"[function_response: {part.function_response.name} → {part.function_response.response}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Key takeaway\n",
    "\n",
    "The tool-use cycle is:\n",
    "\n",
    "**You → Model:** \"What's the weather?\" (+ tool definitions)  \n",
    "**Model → You:** \"Please call `get_weather` with `{\"location\": \"Tokyo\"}`\"  \n",
    "**You → Model:** \"Here's the result: 65 degrees\"  \n",
    "**Model → You:** \"The weather in Tokyo is 65 degrees.\"\n",
    "\n",
    "In the next exercise, we'll automate this into a loop so it can handle multiple tool calls."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
