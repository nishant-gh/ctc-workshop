{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Exercise 3: Multi-turn Conversation\n",
    "\n",
    "In this exercise, you'll build a multi-turn chatbot using Gemini's built-in chat interface.\n",
    "\n",
    "By the end, you'll understand:\n",
    "- The API is **stateless** — it doesn't remember previous messages\n",
    "- Gemini's `client.chats.create()` manages conversation history for you\n",
    "- How `chat.send_message()` handles the message list automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Create a chat and send the first message\n",
    "\n",
    "Unlike manually managing a `messages` list, Gemini provides a `chats.create()` helper that tracks conversation history for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = client.chats.create(model=\"gemini-3-flash-preview\")\n",
    "\n",
    "response = chat.send_message(\"What is the capital of France?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Send a follow-up\n",
    "\n",
    "The chat object automatically tracks history, so follow-up questions just work — no manual message management needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"What is its population?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Inspect the conversation history\n",
    "\n",
    "The chat object stores the full history. Let's look at what's been accumulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in chat._curated_history:\n",
    "    print(f\"--- {msg.role} ---\")\n",
    "    for part in msg.parts:\n",
    "        if part.text:\n",
    "            print(part.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Try it yourself\n",
    "\n",
    "The script version (`chat.py`) wraps this in a `while True` loop with `input()` for an interactive chat. Try running it:\n",
    "\n",
    "```bash\n",
    "uv run python foundation/gemini/03_chat/chat.py\n",
    "```\n",
    "\n",
    "Type `exit` to quit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
