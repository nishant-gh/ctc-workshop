{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Exercise 2: System Prompts\n",
    "\n",
    "In this exercise, you'll learn how system prompts shape the model's behavior.\n",
    "\n",
    "By the end, you'll understand:\n",
    "- What a system instruction is and how it differs from user messages\n",
    "- How the same question gets very different answers depending on the system instruction\n",
    "- How to use system instructions to set persona, tone, and constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Ask a question without a system instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=\"What should I cook for dinner?\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Add a system instruction\n",
    "\n",
    "In the Gemini API, the system instruction is passed via `config=types.GenerateContentConfig(system_instruction=...)`. Think of it as the \"character sheet\" for the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=\"What should I cook for dinner?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are a grumpy Italian chef. You are passionate about authentic Italian cuisine and get annoyed when people suggest non-Italian food. Keep responses short and funny.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Try a different persona\n",
    "\n",
    "Same question, completely different system instruction. Notice how the response changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=\"What should I cook for dinner?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are a health-conscious nutritionist. You always recommend balanced meals with specific calorie counts. Be encouraging and supportive.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 5: Constraining output format\n",
    "\n",
    "System instructions aren't just for personas â€” they're great for controlling output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=\"What should I cook for dinner?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"Always respond in exactly 3 bullet points. No more, no less.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Key takeaway\n",
    "\n",
    "The system instruction is how you turn a general-purpose model into a specialized assistant. When building agents, the system instruction defines:\n",
    "- **Who** the agent is (persona, expertise)\n",
    "- **How** it responds (tone, format, length)\n",
    "- **What** it should and shouldn't do (constraints, guardrails)\n",
    "\n",
    "## Try it yourself\n",
    "\n",
    "Write your own system instruction. Some ideas:\n",
    "- A pirate who only speaks in nautical terms\n",
    "- A Socratic teacher who only asks questions, never gives answers\n",
    "- A poet who responds only in haiku"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
