{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab; uses env var already set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Your First API Call\n",
    "\n",
    "In this exercise, you'll make your first call to the OpenAI API using the Python SDK.\n",
    "\n",
    "By the end, you'll understand:\n",
    "- How to create an OpenAI client\n",
    "- The basic structure of a Chat Completions API call\n",
    "- What the API response looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the client\n",
    "\n",
    "The setup cell above loads your API key from Colab Secrets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Send a message\n",
    "\n",
    "Every API call needs at minimum:\n",
    "- `model` — which model to use\n",
    "- `messages` — a list of messages, each with a `role` and `content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What are three fun facts about the moon?\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the response\n",
    "\n",
    "Let's look at the full response object first to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response contains:\n",
    "- `id` — a unique identifier for this request\n",
    "- `model` — the model that was used\n",
    "- `choices` — a list of completions (usually one), each with a `message`\n",
    "- `usage` — token counts for input and output\n",
    "\n",
    "Each choice has:\n",
    "- `message.content` — the text response\n",
    "- `finish_reason` — why the model stopped (`stop`, `length`, `tool_calls`)\n",
    "\n",
    "To get just the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself\n",
    "\n",
    "Change the user message to ask something different and re-run the cells above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
