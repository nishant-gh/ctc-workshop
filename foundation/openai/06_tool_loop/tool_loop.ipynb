{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab; uses env var already set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: The Agentic Loop\n",
    "\n",
    "In this exercise, we put it all together into an **agent loop** — the core pattern behind AI agents.\n",
    "\n",
    "By the end, you'll understand:\n",
    "- How to build a loop that keeps running until the model stops requesting tools\n",
    "- How to dispatch tool calls to actual functions\n",
    "- How the model can chain **multiple** tool calls to answer a single question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "from datetime import datetime\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define multiple tools and a dispatcher\n",
    "\n",
    "This time we have **two** tools. The `call_tool` function maps tool names to their implementations — this is how real agents work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_time\",\n",
    "            \"description\": \"Get the current date and time\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def call_tool(tool_name, tool_input):\n",
    "    if tool_name == \"get_weather\":\n",
    "        return f\"72°F and sunny in {tool_input['location']}\"\n",
    "    elif tool_name == \"get_time\":\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    else:\n",
    "        return \"Tool not found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The agent loop\n",
    "\n",
    "This is the core pattern. The loop:\n",
    "1. Sends messages to the model\n",
    "2. Checks if the response contains any `tool_calls`\n",
    "3. If yes — executes each tool, appends results, and loops back to step 1\n",
    "4. If no — the model is done, we print the final text and break\n",
    "\n",
    "Because we ask about **both** weather and time, the model needs to call two tools — watch the loop iterate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather and current time in Tokyo?\"}]\n",
    "\n",
    "loop_count = 0\n",
    "\n",
    "while True:\n",
    "    loop_count += 1\n",
    "    print(f\"--- Loop iteration {loop_count} ---\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "    print(f\"finish_reason: {response.choices[0].finish_reason}\")\n",
    "\n",
    "    # Add assistant response to messages\n",
    "    messages.append(message)\n",
    "\n",
    "    if message.tool_calls:\n",
    "        for tool_call in message.tool_calls:\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            tool_result = call_tool(tool_call.function.name, args)\n",
    "            print(f\"  Tool: {tool_call.function.name}({args}) → {tool_result}\")\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": tool_result,\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        print(f\"\\n{message.content}\")\n",
    "        print(\"\\nDone! No more tool calls.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Review the full message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in messages:\n",
    "    if hasattr(msg, 'role'):\n",
    "        role = msg.role\n",
    "        content = msg.content or f\"[tool_calls: {[tc.function.name for tc in msg.tool_calls]}]\"\n",
    "    else:\n",
    "        role = msg['role']\n",
    "        content = msg.get('content', '')\n",
    "    print(f\"--- {role} ---\")\n",
    "    print(f\"{content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key takeaway\n",
    "\n",
    "This is the **agentic loop** — the foundation of every AI agent:\n",
    "\n",
    "```\n",
    "while True:\n",
    "    response = call_model(messages)\n",
    "    if response has tool calls:\n",
    "        execute tools, append results\n",
    "    else:\n",
    "        break  # model is done\n",
    "```\n",
    "\n",
    "Everything else — multiple tools, error handling, human-in-the-loop, memory — is built on top of this pattern.\n",
    "\n",
    "Now let's build some real agents!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
