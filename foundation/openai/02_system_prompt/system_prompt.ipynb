{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "except ImportError:\n",
    "    pass  # Not running in Colab; uses env var already set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: System Prompts\n",
    "\n",
    "In this exercise, you'll learn how system prompts shape the model's behavior.\n",
    "\n",
    "By the end, you'll understand:\n",
    "- What a system prompt is and how it differs from user messages\n",
    "- How the same question gets very different answers depending on the system prompt\n",
    "- How to use system prompts to set persona, tone, and constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Ask a question without a system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What should I cook for dinner?\"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add a system prompt\n",
    "\n",
    "In the OpenAI API, the system prompt is a message with `role: \"system\"` placed **first** in the messages list. Think of it as the \"character sheet\" for the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a grumpy Italian chef. You are passionate about authentic Italian cuisine and get annoyed when people suggest non-Italian food. Keep responses short and funny.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What should I cook for dinner?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Try a different persona\n",
    "\n",
    "Same question, completely different system prompt. Notice how the response changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a health-conscious nutritionist. You always recommend balanced meals with specific calorie counts. Be encouraging and supportive.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What should I cook for dinner?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Constraining output format\n",
    "\n",
    "System prompts aren't just for personas â€” they're great for controlling output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Always respond in exactly 3 bullet points. No more, no less.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What should I cook for dinner?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key takeaway\n",
    "\n",
    "The system prompt is how you turn a general-purpose model into a specialized assistant. When building agents, the system prompt defines:\n",
    "- **Who** the agent is (persona, expertise)\n",
    "- **How** it responds (tone, format, length)\n",
    "- **What** it should and shouldn't do (constraints, guardrails)\n",
    "\n",
    "## Try it yourself\n",
    "\n",
    "Write your own system prompt. Some ideas:\n",
    "- A pirate who only speaks in nautical terms\n",
    "- A Socratic teacher who only asks questions, never gives answers\n",
    "- A poet who responds only in haiku"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
